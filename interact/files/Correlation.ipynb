{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04509dd7",
   "metadata": {},
   "source": [
    "# Correlation\n",
    "\n",
    "{ucb-page}`Correlation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec17e65a",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "import numpy as np\n",
    "# Make random number generator.\n",
    "rng = np.random.default_rng()\n",
    "import pandas as pd\n",
    "pd.set_option('mode.copy_on_write', True)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa02f269",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "def r_scatter(r):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    \"Generate a scatter plot with a correlation approximately r\"\n",
    "    x = rng.normal(0, 1, 1000)\n",
    "    z = rng.normal(0, 1, 1000)\n",
    "    y = r*x + (np.sqrt(1-r**2))*z\n",
    "    plt.scatter(x, y)\n",
    "    plt.xlim(-4, 4)\n",
    "    plt.ylim(-4, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8c3563",
   "metadata": {},
   "source": [
    "## Correlation ##\n",
    "\n",
    "In this section we will develop a measure of how tightly clustered\n",
    "a scatter diagram is about a straight line. Formally, this is called\n",
    "measuring *linear association*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85e6cd7",
   "metadata": {},
   "source": [
    "The table `hybrid` contains data on hybrid passenger cars sold in the\n",
    "United States from 1997 to 2013. The data were adapted from the online\n",
    "data archive of [Prof. Larry Winner](http://www.stat.ufl.edu/%7Ewinner/)\n",
    "of the University of Florida. The columns:\n",
    "\n",
    "- `vehicle`: model of the car\n",
    "- `year`: year of manufacture\n",
    "- `msrp`: manufacturer's suggested retail price in 2013 dollars\n",
    "- `acceleration`: acceleration rate in km per hour per second\n",
    "- `mpg`: fuel economy in miles per gallon\n",
    "- `class`: the model's class.\n",
    "\n",
    "You can download the file via {download}`hybrid.csv <data/hybrid.csv>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a215816d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid = pd.read_csv('data/hybrid.csv')\n",
    "hybrid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ffd5f5",
   "metadata": {},
   "source": [
    "The graph below is a scatter plot of `msrp` *versus* `acceleration`.\n",
    "That means `msrp` is plotted on the vertical axis and `acceleration` on\n",
    "the horizontal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b7c328",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid.plot.scatter('acceleration', 'msrp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47cd9b5",
   "metadata": {},
   "source": [
    "Notice the positive association. The scatter of points is sloping\n",
    "upwards, indicating that cars with greater acceleration tended to cost\n",
    "more, on average; conversely, the cars that cost more tended to have\n",
    "greater acceleration on average.\n",
    "\n",
    "The scatter diagram of MSRP versus miles per gallon shows a negative\n",
    "association. Hybrid cars with higher miles per gallon tended to cost\n",
    "less, on average. This seems surprising till you consider that cars that\n",
    "accelerate fast tend to be less fuel efficient and have lower miles per\n",
    "gallon. As the previous scatter plot showed, those were also the cars\n",
    "that tended to cost more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9118c5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid.plot.scatter('mpg', 'msrp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3fd14d",
   "metadata": {},
   "source": [
    "Along with the negative association, the scatter diagram of price versus\n",
    "efficiency shows a non-linear relation between the two variables. The\n",
    "points appear to be clustered around a curve, not around a straight\n",
    "line.\n",
    "\n",
    "If we restrict the data just to the SUV class, however, the association\n",
    "between price and efficiency is still negative but the relation appears\n",
    "to be more linear. The relation between the price and acceleration of\n",
    "SUVs also shows a linear trend, but with a positive slope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fded4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "suv = hybrid[hybrid['class'] == 'SUV']\n",
    "suv.plot.scatter('mpg', 'msrp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941e47b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "suv.plot.scatter('acceleration', 'msrp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1fcea6",
   "metadata": {},
   "source": [
    "You will have noticed that we can derive useful information from the\n",
    "general orientation and shape of a scatter diagram even without paying\n",
    "attention to the units in which the variables were measured.\n",
    "\n",
    "Indeed, we could plot all the variables in standard units and the plot\n",
    "would look the same. This gives us a way to compare the degree of\n",
    "linearity in two scatter diagrams.\n",
    "\n",
    "Recall that in an earlier section we defined the function\n",
    "`standard_units` to convert an array of numbers to standard units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce45c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_units(x):\n",
    "    \"Convert any array of numbers to standard units.\"\n",
    "    return (x - np.mean(x))/np.std(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22968348",
   "metadata": {},
   "source": [
    "We can use this function to re-draw the two scatter diagrams for SUVs,\n",
    "with all the variables measured in standard units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce1e8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "suv_mpg_su = standard_units(suv['mpg'])\n",
    "suv_msrp_su = standard_units(suv['msrp'])\n",
    "plt.plot(suv_mpg_su, suv_msrp_su, 'o')\n",
    "plt.xlabel('mpg (standard units)')\n",
    "plt.ylabel('msrp (standard units)')\n",
    "plt.xlim(-3, 3)\n",
    "plt.ylim(-3, 3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13868394",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(standard_units(suv['acceleration']),\n",
    "         standard_units(suv['msrp']), 'o')\n",
    "plt.xlabel('acceleration (standard units)')\n",
    "plt.ylabel('msrp (standard units)')\n",
    "plt.xlim(-3, 3)\n",
    "plt.ylim(-3, 3);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c3569c",
   "metadata": {},
   "source": [
    "The associations that we see in these figures are the same as those we\n",
    "saw before. Also, because the two scatter diagrams are now drawn on\n",
    "exactly the same scale, we can see that the linear relation in the\n",
    "second diagram is a little more fuzzy than in the first.\n",
    "\n",
    "We will now define a measure that uses standard units to quantify the\n",
    "kinds of association that we have seen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0039d872",
   "metadata": {},
   "source": [
    "## The correlation coefficient ##\n",
    "\n",
    "The *correlation coefficient* measures the strength of the linear\n",
    "relationship between two variables. Graphically, it measures how\n",
    "clustered the scatter diagram is around a straight line.\n",
    "\n",
    "The term *correlation coefficient* isn't easy to say, so it is usually\n",
    "shortened to *correlation* and denoted by $r$.\n",
    "\n",
    "Here are some mathematical facts about $r$ that we will just observe by\n",
    "simulation.\n",
    "\n",
    "- The correlation coefficient $r$ is a number between $-1$ and 1.\n",
    "- $r$ measures the extent to which the scatter plot clusters around\n",
    "  a straight line.\n",
    "- $r = 1$ if the scatter diagram is a perfect straight line sloping\n",
    "  upwards, and $r = -1$ if the scatter diagram is a perfect straight\n",
    "  line sloping downwards."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c461e9a2",
   "metadata": {},
   "source": [
    "The function ``r_scatter`` takes a value of $r$ as its argument and\n",
    "simulates a scatter plot with a correlation very close to $r$. Because\n",
    "of randomness in the simulation, the correlation is not expected to be\n",
    "exactly equal to $r$.\n",
    "\n",
    "Call ``r_scatter`` a few times, with different values of $r$ as the\n",
    "argument, and see how the scatter plot changes.\n",
    "\n",
    "When $r=1$ the scatter plot is perfectly linear and slopes upward. When\n",
    "$r=-1$, the scatter plot is perfectly linear and slopes downward. When\n",
    "$r=0$, the scatter plot is a formless cloud around the horizontal axis,\n",
    "and the variables are said to be *uncorrelated*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea3948b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_scatter(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995ccf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_scatter(0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47ed793",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_scatter(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec15fd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_scatter(-0.55)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9d517b",
   "metadata": {},
   "source": [
    "## $r$ is the least squares slope in standard units\n",
    "\n",
    "Imagine we are interested in the least squares straight line relating the 'mpg' values *in standard units* to the 'mrsp' values *in standard units*.\n",
    "\n",
    "We would follow the recipe we know from our previous regressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1d887d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_any_line(c_s, x_values, y_values):\n",
    "    c, s = c_s\n",
    "    predicted = c + x_values * s\n",
    "    error = y_values - predicted\n",
    "    return np.sqrt(np.mean(error ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0b3b14",
   "metadata": {},
   "source": [
    "Find the best intercept and slope:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b75ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "best_c, best_s = minimize(rmse_any_line, [0, -0.5],\n",
    "                          args=(suv_mpg_su, suv_msrp_su)).x\n",
    "print('Intercept', best_c)\n",
    "print('Slope', best_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc4afc5",
   "metadata": {},
   "source": [
    "Notice that the intercept is exactly (or very close to) zero.  In fact, it turns out that\n",
    "this will always be so *when we calculate the line on arrays in standard\n",
    "units*.\n",
    "\n",
    "The slope is $r$ - the correlation coefficient.\n",
    "\n",
    "**The correlation coefficient is the least-squares slope between the two input arrays that have been converted to standard units**.\n",
    "\n",
    "We will soon see that we can get this same value, without using `minimize`, using a simple calculation on the x and y values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29194e8",
   "metadata": {},
   "source": [
    "## $r$ by calculation\n",
    "\n",
    "The formula for $r$ is not apparent from our observations so far. It has\n",
    "a mathematical basis that is outside the scope of this class. However,\n",
    "as you will see, the calculation is straightforward and helps us\n",
    "understand several of the properties of $r$.\n",
    "\n",
    "**Formula for $r$**:\n",
    "\n",
    "**$r$ is the average of the products of the two variables, when both\n",
    "variables are measured in standard units.**\n",
    "\n",
    "Here are the steps in the calculation. We will apply the steps to\n",
    "a simple table of values of $x$ and $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bf9b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(1, 7)\n",
    "y = np.array([2, 3, 1, 5, 2, 7])\n",
    "t = pd.DataFrame()\n",
    "t['x'] = x\n",
    "t['y'] = y\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a09a3e",
   "metadata": {},
   "source": [
    "Based on the scatter diagram, we expect that $r$ will be positive but\n",
    "not equal to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401424b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.plot.scatter('x', 'y', s=30, color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8a7b47",
   "metadata": {},
   "source": [
    "**Step 1.** Convert each variable to standard units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e9d900",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_su = pd.DataFrame()\n",
    "t_su['x (standard units)'] = standard_units(x)\n",
    "t_su['y (standard units)'] = standard_units(y)\n",
    "t_su"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5c5922",
   "metadata": {},
   "source": [
    "**Step 2.** Multiply each pair of standard units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f859da92",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_product = t_su['x (standard units)'] * t_su['y (standard units)']\n",
    "t_su['product of standard units'] = t_product\n",
    "t_su"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674e117b",
   "metadata": {},
   "source": [
    "**Step 3.** $r$ is the average of the products computed in Step 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453b65e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r is the average of the products of standard units\n",
    "r = np.mean(t_su['product of standard units'])\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cbbd95",
   "metadata": {},
   "source": [
    "As expected, $r$ is positive but not equal to 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8706c03",
   "metadata": {},
   "source": [
    "## Properties of $r$\n",
    "\n",
    "The calculation shows that:\n",
    "\n",
    "- $r$ is a pure number. It has no units. This is because $r$ is based on\n",
    "  standard units.\n",
    "- $r$ is unaffected by changing the units on either axis. This too is\n",
    "  because $r$ is based on standard units.\n",
    "- $r$ is unaffected by switching the axes. Algebraically, this is\n",
    "  because the product of standard units does not depend on which\n",
    "  variable is called $x$ and which $y$. Geometrically, switching axes\n",
    "  reflects the scatter plot about the line $y=x$, but does not change\n",
    "  the amount of clustering nor the sign of the association."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7373a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.plot.scatter('y', 'x', s=30, color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86cd025",
   "metadata": {},
   "source": [
    "### The `correlation` function\n",
    "\n",
    "We are going to be calculating correlations repeatedly, so it will help\n",
    "to define a function that computes it by performing all the steps\n",
    "described above. Let's define a function ``correlation`` that takes\n",
    "a table and the labels of two columns in the table. The function returns\n",
    "$r$, the mean of the products of those column values in standard units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c7deef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(t, x_name, y_name):\n",
    "    \"\"\" Correlation by calculation\n",
    "    \"\"\"\n",
    "    x = t[x_name]\n",
    "    y = t[y_name]\n",
    "    return np.mean(standard_units(x) * standard_units(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78633053",
   "metadata": {},
   "source": [
    "This is a `minimize` version of the function - it will return very similar results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ac25c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_minimize(t, x_name, y_name):\n",
    "    \"\"\" Correlation by minimization\n",
    "    \"\"\"\n",
    "    x = t[x_name]\n",
    "    y = t[y_name]\n",
    "    x_su, y_su = standard_units(x), standard_units(y)\n",
    "    intercept, slope = minimize(rmse_any_line, [0, 1], args=(x_su, y_su)).x\n",
    "    if not np.isclose(intercept, 0):\n",
    "        print('Oh dear, intercept not near 0')\n",
    "    return slope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4c44a4",
   "metadata": {},
   "source": [
    "Let's call the function on the ``x`` and ``y`` columns of ``t``. The\n",
    "function returns the same answer to the correlation between $x$ and $y$\n",
    "as we got by direct application of the formula for $r$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c08d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation(t, 'x', 'y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6a0e8a",
   "metadata": {},
   "source": [
    "The minimize version returns almost exactly the same result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f70b7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_minimize(t, 'x', 'y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fad61a",
   "metadata": {},
   "source": [
    "As we noticed, the order in which the variables are specified doesn't\n",
    "matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9a1810",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation(t, 'y', 'x')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826c1f51",
   "metadata": {},
   "source": [
    "Calling ``correlation`` on columns of the table ``suv`` gives us the\n",
    "correlation between price and miles per gallon as well as the\n",
    "correlation between price and acceleration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192d0816",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation(suv, 'mpg', 'msrp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32045c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation(suv, 'acceleration', 'msrp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd6c36a",
   "metadata": {},
   "source": [
    "These values confirm what we had observed:\n",
    "\n",
    "- There is a negative association between price and efficiency, whereas\n",
    "  the association between price and acceleration is positive.\n",
    "- The linear relation between price and acceleration is a little weaker\n",
    "  (correlation about 0.5) than between price and miles per gallon\n",
    "  (correlation about -0.67)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f04146",
   "metadata": {},
   "source": [
    "Correlation is a simple and powerful concept, but it is sometimes\n",
    "misused. Before using $r$, it is important to be aware of what\n",
    "correlation does and does not measure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049e43eb",
   "metadata": {},
   "source": [
    "## A Permutation Test for the Correlation Coefficient ##\n",
    "\n",
    "We can perform a permutation test for the correlation coefficient in a very similar manner to the\n",
    "permutation tests we have seen previously.\n",
    "\n",
    "Our *null world* is one where there is no correlation between `acceleration` and `msrp`. If we are actually in the *null world*\n",
    "then any correlation we observe in our sample must be a *fluke* - it just happens to occur\n",
    "in our sample, but does not occur in the population beyond our sample.\n",
    "\n",
    "We can simulate drawing many samples from the *null world* by shuffling the standard scores\n",
    "from which we calculate the correlation coefficient. If we repeat this process lots of times\n",
    "we can build a picture of the sort of correlation coefficient values we would expect in the\n",
    "*null world*.\n",
    "\n",
    "If our actual correlation coefficient value is very different from these simulated *null world* values,\n",
    "then we can conclude that the *null world* is not a good model of the actual world.\n",
    "\n",
    "Let's look again at the `acceleration` and `msrp` data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdd7a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(standard_units(hybrid['acceleration']),\n",
    "         standard_units(hybrid['msrp']), 'o')\n",
    "plt.xlabel('acceleration (standard units)')\n",
    "plt.ylabel('msrp (standard units)')\n",
    "plt.xlim(-3, 3)\n",
    "plt.ylim(-3, 3);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf0791e",
   "metadata": {},
   "source": [
    "As we know, we can calculate the correlation coefficient by converting each variable to standard scores,\n",
    "multiplying the standard scores together, and then taking the mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262d5368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# each variable in standard scores\n",
    "r = np.mean(standard_units(hybrid['acceleration']) * standard_units(hybrid['msrp']))\n",
    "\n",
    "# show the correlation coefficient\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e3e7ef",
   "metadata": {},
   "source": [
    "We want to know if this observed correlation is consistent with the *null world* - is it possible this is just a fluke correlation we observe in our sample, but is unreflective of the correlation in the population from which the sample came?\n",
    "\n",
    "The permutation test is performed in the cell below.\n",
    "\n",
    "We shuffle the standard scores from one of the variables (or both!) to destroy the relationship between the two variables. (Remember, if the *null world* is true, there is no correlation between the variables). We then calculate the correlation coefficient using this shuffled data.\n",
    "\n",
    "We repeat this process many times to get an idea of the range of correlation coefficients we would expect if the *null world* is true:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44404339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of iterations for the permutation test\n",
    "n_iters = 10_000\n",
    "\n",
    "# an empty array to store the results\n",
    "results = np.zeros(n_iters)\n",
    "\n",
    "# for 10_000 repeats...\n",
    "for i in np.arange(n_iters):\n",
    "\n",
    "    # shuffle the standard scores\n",
    "    shuffled_standard_acceleration = rng.permutation(standard_units(hybrid['acceleration']))\n",
    "\n",
    "    # calculate the fake correlation coefficient\n",
    "    fake_correlation_coefficient = np.mean(shuffled_standard_acceleration * standard_units(hybrid['msrp']))\n",
    "\n",
    "    # store the fake correlation\n",
    "    results[i] = fake_correlation_coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70afeaa9",
   "metadata": {},
   "source": [
    "We can then plot the results of the simulation, as well as the correlation coefficient\n",
    "we got from the actual data, to see if how (un)likely our actual coefficient would be, in\n",
    "the null world:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26c9ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the simulation results\n",
    "plt.hist(results)\n",
    "plt.xlabel('Correlation Coefficient Value')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# plot the correlation coefficient from the real data\n",
    "plt.axvline(r, color='red', label='actual correlation')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf55cec",
   "metadata": {},
   "source": [
    "We can get a specific probability value (a $p$-value) by counting the number of simulated\n",
    "correlation coefficients that were as extreme or more extreme than the actual coefficient we observed.\n",
    "\n",
    "*Note:* we have used `np.abs()` here to compare the *magnitude* of the simulated correlation coefficients\n",
    "to the actual correlation coefficient, ignoring the direction (+ or -) of the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1bcc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value = np.count_nonzero(np.abs(results) >= np.abs(r))/n_iters\n",
    "\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6bb975",
   "metadata": {},
   "source": [
    "This p-value is 0, meaning we never observed a correlation in the simulation that is as large as the\n",
    "actual correlation we observed in our sample\n",
    "\n",
    "From this we can conclude that the *null world* is not a good model of the actual world. We can take this\n",
    "as evidence that a nonzero correlation exists in the actual world, outside of our sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80307b95",
   "metadata": {},
   "source": [
    "### Association is not Causation\n",
    "\n",
    "Correlation only measures association. Correlation does not imply\n",
    "causation. Though the correlation between the weight and the math\n",
    "ability of children in a school district may be positive, that does not\n",
    "mean that doing math makes children heavier or that putting on weight\n",
    "improves the children's math skills. Age is a confounding variable:\n",
    "older children are both heavier and better at math than younger\n",
    "children, on average.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2def9b",
   "metadata": {},
   "source": [
    "### Correlation Measures *Linear* Association\n",
    "\n",
    "Correlation measures only one kind of association – linear. Variables\n",
    "that have strong non-linear association might have very low correlation.\n",
    "Here is an example of variables that have a perfect quadratic relation\n",
    "$y = x^2$ but have correlation equal to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3f8a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x = np.arange(-4, 4.1, 0.5)\n",
    "nonlinear = pd.DataFrame()\n",
    "nonlinear['x'] = new_x\n",
    "nonlinear['y'] = new_x ** 2\n",
    "nonlinear.plot.scatter('x', 'y', s=30, color='r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb85a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation(nonlinear, 'x', 'y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dad55a2",
   "metadata": {},
   "source": [
    "### Correlation is Affected by Outliers\n",
    "\n",
    "Outliers can have a big effect on correlation. Here is an example where\n",
    "a scatter plot for which $r$ is equal to 1 is turned into a plot for\n",
    "which $r$ is equal to 0, by the addition of just one outlying point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbec805",
   "metadata": {},
   "outputs": [],
   "source": [
    "line = pd.DataFrame()\n",
    "line['x'] = np.array([1, 2, 3, 4])\n",
    "line['y'] = np.array([1, 2, 3, 4])\n",
    "line.plot.scatter('x', 'y', s=30, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe8c55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation(line, 'x', 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be72ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier = pd.DataFrame()\n",
    "outlier['x'] = np.array([1, 2, 3, 4, 5])\n",
    "outlier['y'] = np.array([1, 2, 3, 4, 0])\n",
    "outlier.plot.scatter('x', 'y', s=30, color='r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76368cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation(outlier, 'x', 'y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f496d0e",
   "metadata": {},
   "source": [
    "### Ecological Correlations Should be Interpreted with Care\n",
    "\n",
    "Correlations based on aggregated data can be misleading. As an example,\n",
    "here are data on the Critical Reading and Math SAT scores in 2014. There\n",
    "is one point for each of the 50 states and one for Washington, D.C. The\n",
    "column ``Participation Rate`` contains the percent of high school\n",
    "seniors who took the test. The next three columns show the average score\n",
    "in the state on each portion of the test, and the final column is the\n",
    "average of the total scores on the test.\n",
    "\n",
    "You can download the file via {download}`sat2014.csv <data/sat2014.csv>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a3b334",
   "metadata": {},
   "outputs": [],
   "source": [
    "sat2014 = pd.read_csv('data/sat2014.csv').sort_values('State')\n",
    "sat2014.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc49a30e",
   "metadata": {},
   "source": [
    "The scatter diagram of Math scores versus Critical Reading scores is\n",
    "very tightly clustered around a straight line; the correlation is close\n",
    "to 0.985."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2761fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sat2014.plot.scatter('Critical Reading', 'Math')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fe382b",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation(sat2014, 'Critical Reading', 'Math')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081083ad",
   "metadata": {},
   "source": [
    "That's an extremely high correlation. But it's important to note that\n",
    "this does not reflect the strength of the relation between the Math and\n",
    "Critical Reading scores of *students*.\n",
    "\n",
    "The data consist of average scores in each state. But states don't take\n",
    "tests – students do. The data in the table have been created by lumping\n",
    "all the students in each state into a single point at the average values\n",
    "of the two variables in that state. But not all students in the state\n",
    "will be at that point, as students vary in their performance. If you\n",
    "plot a point for each student instead of just one for each state, there\n",
    "will be a cloud of points around each point in the figure above. The\n",
    "overall picture will be more fuzzy. The correlation between the Math and\n",
    "Critical Reading scores of the students will be *lower* than the value\n",
    "calculated based on state averages.\n",
    "\n",
    "Correlations based on aggregates and averages are called *ecological\n",
    "correlations* and are frequently reported. As we have just seen, they\n",
    "must be interpreted with care.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1704babf",
   "metadata": {},
   "source": [
    "### Serious or tongue-in-cheek?\n",
    "\n",
    "In 2012,\n",
    "a [paper](http://www.biostat.jhsph.edu/courses/bio621/misc/Chocolate%20consumption%20cognitive%20function%20and%20nobel%20laurates%20%28NEJM%29.pdf)\n",
    "in the respected New England Journal of Medicine examined the relation\n",
    "between chocolate consumption and Nobel Prizes in a group of countries.\n",
    "The [Scientific\n",
    "American](http://blogs.scientificamerican.com/the-curious-wavefunction/chocolate-consumption-and-nobel-prizes-a-bizarre-juxtaposition-if-there-ever-was-one/)\n",
    "responded seriously whereas\n",
    "[others](https://www.reuters.com/article/us-eat-chocolate-win-the-nobel-prize-idUSBRE8991MS20121010)\n",
    "were more relaxed. You are welcome to make your own decision! The\n",
    "following graph, provided in the paper, should motivate you to go and\n",
    "take a look.\n",
    "\n",
    "![](images/chocoNobel.png)\n",
    "\n",
    "{ucb-page}`Correlation`"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python (Pyodide)",
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
